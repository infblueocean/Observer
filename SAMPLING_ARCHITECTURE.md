# Sampling Architecture

## Overview

A decoupled architecture for feed sampling that separates source management from display sampling. This enables:
- Adaptive polling based on source activity
- Pluggable sampling strategies
- Clean separation of concerns
- Natural handling of "bursty" vs "quiet" sources without special detection

**Core Philosophy**: "Firehose to DB, curated to UI"
- Polling stores everything (complete record)
- Sampling controls what appears (balanced exposure)

---

## Current Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           SOURCE QUEUES                                  â”‚
â”‚                                                                          â”‚
â”‚  Each source maintains its own queue of items (newest first) and        â”‚
â”‚  adapts its polling interval based on observed activity.                 â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   Reuters    â”‚  â”‚     SEC      â”‚  â”‚    Nikkei    â”‚   ... Ã—200+      â”‚
â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                   â”‚
â”‚  â”‚ items: 15    â”‚  â”‚ items: 127   â”‚  â”‚ items: 89    â”‚                   â”‚
â”‚  â”‚ poll: 45s    â”‚  â”‚ poll: 8m     â”‚  â”‚ poll: 3m     â”‚   â† adaptive     â”‚
â”‚  â”‚ lastPoll: .. â”‚  â”‚ lastPoll: .. â”‚  â”‚ lastPoll: .. â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SAMPLER INTERFACE                                â”‚
â”‚                                                                          â”‚
â”‚  type Sampler interface {                                                â”‚
â”‚      Sample(queues []*SourceQueue, n int) []feeds.Item                   â”‚
â”‚  }                                                                       â”‚
â”‚                                                                          â”‚
â”‚  The sampler is agnostic to source chattiness - it just pulls from      â”‚
â”‚  queues according to its strategy.                                       â”‚
â”‚                                                                          â”‚
â”‚  Implementations:                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ RoundRobin      â”‚ â”‚ DeficitRR       â”‚ â”‚ FairRecent      â”‚            â”‚
â”‚  â”‚ Simple rotation â”‚ â”‚ Credit-based    â”‚ â”‚ Quota + recency â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ WeightedRR      â”‚ â”‚ ThrottledRecencyâ”‚ â”‚ RecencyMerge    â”‚            â”‚
â”‚  â”‚ By source weightâ”‚ â”‚ Caps + recency  â”‚ â”‚ Global newest   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           STREAM VIEW                                    â”‚
â”‚                                                                          â”‚
â”‚  Displays whatever the sampler provides. Time bands, interleaving,      â”‚
â”‚  and visual presentation remain here.                                    â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Adaptive Polling

Instead of fixed refresh intervals, sources adapt based on observed activity:

```
                    Found new items
                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚                     â”‚
    â–¼                     â”‚                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SPEED  â”‚                â”‚              â”‚   SLOW     â”‚
â”‚  UP    â”‚                â”‚              â”‚   DOWN     â”‚
â”‚        â”‚                â”‚              â”‚            â”‚
â”‚ Ã—0.7   â”‚                â”‚              â”‚   Ã—1.5     â”‚
â”‚        â”‚                â”‚              â”‚            â”‚
â”‚ floor: â”‚                â”‚              â”‚ ceiling:   â”‚
â”‚  30s   â”‚                â”‚              â”‚   15min    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                   No new items
```

**Behavior:**
- Source with frequent updates (Reuters): settles around 30-60s
- Source with rare updates (academic blog): settles around 10-15min
- Source that suddenly has news: quickly adapts down to floor
- "Burst detection" becomes unnecessary - adaptive polling handles it naturally

---

## Sampler Strategies

### Core Principle: Two-Stage Sampling

From brain trust recommendations (GPT-5, Grok-4):

1. **Choose a source** under fairness/weights/exploration rules
2. **Choose item(s) within that source** under recency/quality rules

This prevents "one chatty source dominates" while keeping per-source queues useful.

---

### Implemented Samplers

#### 1. RoundRobinSampler
**Purpose**: Simple balanced view with equal representation.

Takes one item from each source in rotation. Ensures every source gets representation regardless of how many items they have.

```
Queue A: [A1, A2, A3, A4, A5]
Queue B: [B1, B2]
Queue C: [C1, C2, C3]

Sample(6) â†’ [A1, B1, C1, A2, B2, C2]
```

**Config**:
- `MaxPerSource`: Cap items per source (0 = no limit)

**Good for**: Simple balanced view, testing.

---

#### 2. DeficitRoundRobinSampler (Recommended Default)
**Purpose**: Strict long-run fairness even with bursty sources.
**Source**: GPT-5's top recommendation for fairness.

Each source accumulates "credit" (deficit) based on its weight. Items are emitted when credit >= 1.0. This handles sources that are empty for a while then explode with content.

```go
// Each sampling tick:
deficit[source] += quantum * weight
while deficit[source] >= 1.0 && source.hasItems():
    emit(source.next())
    deficit[source] -= 1.0
```

**Config**:
- `Quantum`: Credit added per round (default 1.0)
- `MaxPerSource`: Cap items per source per sample

**Why better than plain RoundRobin**: When source A has 0 items and source B has 100, plain RR would skip A. DRR accumulates credit for A, so when A finally publishes, it gets fair representation.

**Good for**: Balanced view, front page, default stream.

---

#### 3. FairRecentSampler (Balanced + Fresh)
**Purpose**: Combine fairness quotas with recency preference.
**Source**: Grok-4's top recommendation.

1. Take up to N items per source from recent window (default 24h)
2. Sort all candidates by recency (newest first)
3. Optional: apply per-source cooldown (minimum spacing)

```
Config: QuotaPerSource=20, MaxAge=24h

SEC (127 items)     â†’ takes 20 newest
Reuters (15 items)  â†’ takes all 15
Academic (3 items)  â†’ takes all 3

Sort by recency â†’ return top N
```

**Config**:
- `QuotaPerSource`: Max items per source (default 20)
- `MaxAge`: Filter out items older than this (default 24h)
- `PerSourceCooldown`: Minimum items between same source (default 0)

**Good for**: Default stream view, "what's happening" with balance.

---

#### 4. ThrottledRecencySampler (Breaking News)
**Purpose**: Recency-first with per-source caps to prevent firehose dominance.
**Source**: GPT-5's recommendation for "Recent" view.

1. Sort all items by recency (newest first)
2. Take items, capping each source at MaxPerSource

```
Config: MaxPerSource=3

Firehose source publishes 50 items in 10 minutes
â†’ Only 3 make it to the view
â†’ Other sources still get representation
```

**Config**:
- `MaxPerSource`: Cap items per source in result (default 3)

**Good for**: Breaking news view, "right now" without firehose dominance.

---

#### 5. WeightedRoundRobinSampler
**Purpose**: Editorial control via source weights.

Sources have weights (wire services > blogs). Higher weight = more items sampled proportionally.

```
Reuters (weight 2.0): gets ~2x items
Tech blog (weight 0.5): gets ~0.5x items
```

Uses credit system similar to DRR but normalized by average weight.

**Config**:
- `MinWeight`: Sources below this are skipped (default 0.1)

**Good for**: Trusted sources priority, editorial curation.

---

#### 6. RecencyMergeSampler
**Purpose**: Pure recency, ignore source boundaries.

Collects all items from all queues, sorts by published time, returns top N.

**Warning**: Can let chatty sources dominate. Use with per-source caps if needed.

**Good for**: "What's happening right now" when you don't care about balance.

---

### Recommended View Recipes

| View | Sampler | Config | Rationale |
|------|---------|--------|-----------|
| **Default Stream** | FairRecentSampler | QuotaPerSource=20, MaxAge=24h | Balanced + fresh |
| **Breaking News** | ThrottledRecencySampler | MaxPerSource=3 | Recency without firehose |
| **Front Page** | DeficitRoundRobinSampler | Weighted | Strict fairness |
| **Firehose** | RecencyMergeSampler | (none) | Raw chronological |
| **Curated** | WeightedRoundRobinSampler | Custom weights | Editorial control |

---

## Brain Trust Insights

### GPT-5 Recommendations

#### Fairness Strategies

| Strategy | Description | Implementation |
|----------|-------------|----------------|
| **Deficit Round Robin (DRR)** | Credit-based emission, strict long-run fairness | `DeficitRoundRobinSampler` |
| **Exposure caps (sliding window)** | Max N per source in last M items shown | Config option |
| **Target-share controller** | Maintain exposure ratios, correct drift | Future enhancement |

#### Anti-Domination Tactics

1. **Hard caps**: Max 3 items per source in any sample
2. **Sliding window caps**: Max 5 items per source in last 50 shown
3. **Cooldown**: Minimum spacing between same-source items (implemented in FairRecentSampler)

#### Advanced Strategies (Future)

- **MMR (Maximal Marginal Relevance)**: Re-rank for topic diversity
- **Stratified quotas by topic**: Allocate slots per topic category
- **Constrained contextual bandit**: Engagement optimization with fairness floors
- **Interest decay**: Anti-obsession for repeated topic exposure

### Grok-4 Recommendations

#### Core Pattern: FairRecent

```python
def sample(stories, count):
    recent = [s for s in stories if (now - s.pub_ts) < 24h]
    quota = defaultdict(list)
    for s in recent:
        quota[s.source_id].append(s)
    balanced = []
    for src, lst in quota.items():
        balanced.extend(lst[:20])  # quota
    return sorted(balanced, key=lambda s: s.pub_ts)[-count:]
```

#### Recommended Metrics

Track per view:
- **Source entropy / Gini**: Measure fairness (lower Gini = more balanced)
- **Duplicate rate**: Cluster collisions (needs correlation engine)
- **Median age**: How fresh is the view
- **Topic entropy**: Diversity (needs topic classification)

---

## Advanced Architecture (Future)

### Per-Source Queuing with Worker Pools

From Grok's architecture feedback, the next evolution adds:
1. **Bounded channels** for backpressure
2. **Worker pool** for GPU-efficient batching
3. **Reranking step** before display

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PER-SOURCE QUEUING (Future)                          â”‚
â”‚                                                                          â”‚
â”‚  SourceHandler A â†’ chan[200] â”€â”                                         â”‚
â”‚  SourceHandler B â†’ chan[200] â”€â”¼â†’ Fan-in â†’ Worker Pool â†’ Reranker        â”‚
â”‚  SourceHandler C â†’ chan[200] â”€â”˜                                         â”‚
â”‚                                                                          â”‚
â”‚  Benefits:                                                               â”‚
â”‚  â€¢ Natural backpressure (bounded channels)                              â”‚
â”‚  â€¢ Fairness per source (per-source caps)                                â”‚
â”‚  â€¢ Easy parallelism (goroutines)                                        â”‚
â”‚  â€¢ Per-source metrics (queue length, latency, errors)                   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Full Pipeline Vision

```
Polling Layer (adaptive intervals)
    â†“
Per-Source Queues (bounded channels, backpressure)
    â†“
Fan-in to Worker Pool (batches across sources)
    â†“
GPU Reranking (jina-reranker-v3 or Qwen3-Reranker-4B)
    â†“
Correlation Engine (clustering, dedup, entity extraction)
    â†“
Samplers (fairness, diversity)
    â†“
Stream View
```

### Reranking Options

| Option | Setup | Performance (RTX 5070) | Fallback |
|--------|-------|------------------------|----------|
| **jina-reranker-v3** | ONNX + Hugot (pure Go) | 7k headlines in 1-4s | CPU: 20-70s |
| **Qwen3-Reranker-4B** | Ollama | 7k headlines in 2-6s | CPU: 20-90s |

Both options:
- Auto-detect GPU (CUDA)
- Graceful CPU fallback
- Batch efficiently (500-2000 items per call)

### Integration with Correlation Engine

The correlation engine (see CORRELATION_ENGINE.md) handles:
- **Duplicate detection**: SimHash on titles
- **Entity extraction**: Tickers, countries, people
- **Clustering**: Group by entity overlap + similarity
- **Disagreement detection**: Conflicting claims

Integration points:
1. Correlation engine removes duplicates BEFORE sampling
2. Reranker scores unique stories
3. Sampler applies fairness on top

### Evolution Path

| Phase | Status | Description |
|-------|--------|-------------|
| 1. Sampling architecture | âœ… Done | SourceQueue, Sampler interface |
| 2. Basic samplers | âœ… Done | RoundRobin, Weighted, Recency |
| 3. Advanced samplers | âœ… Done | DRR, FairRecent, Throttled |
| 4. Correlation engine | ðŸ”œ Next | Clustering, dedup, entities |
| 5. Reranking worker pool | ðŸ”® Future | GPU batching, ML scoring |
| 6. Bounded channels | ðŸ”® Future | Backpressure, metrics |

---

## Source Queue Structure

```go
type SourceQueue struct {
    Name         string
    SourceType   feeds.SourceType
    Weight       float64           // importance weight (default 1.0)

    // Queue state
    items        []feeds.Item      // newest first, soft-ordered
    mu           sync.RWMutex

    // Adaptive polling
    pollInterval time.Duration     // current interval
    basePoll     time.Duration     // configured base (e.g., 5min for newspapers)
    minPoll      time.Duration     // floor (e.g., 30s)
    maxPoll      time.Duration     // ceiling (e.g., 15min)
    lastPoll     time.Time
    lastNewCount int               // items found in last poll

    // Stats
    totalItems   int
    itemsPerDay  float64           // rolling average
}
```

---

## Configuration

```json
{
  "sampling": {
    "strategy": "fair_recent",
    "max_items": 500,
    "fair_recent": {
      "quota_per_source": 20,
      "max_age_hours": 24,
      "cooldown": 0
    },
    "throttled_recency": {
      "max_per_source": 3
    },
    "deficit_rr": {
      "quantum": 1.0,
      "max_per_source": 0
    },
    "adaptive_polling": {
      "enabled": true,
      "min_interval": "30s",
      "max_interval": "15m",
      "speedup_factor": 0.7,
      "slowdown_factor": 1.5
    }
  }
}
```

---

## Benefits

1. **Simpler mental model**: Each source is independent, sampler decides what to show
2. **No special cases**: Burst detection, chatty source caps, etc. all become unnecessary
3. **Testable**: Samplers are pure functions, easy to unit test
4. **Extensible**: New sampling strategies without touching source code
5. **Adaptive**: System naturally adjusts to source behavior
6. **Transparent**: User can understand why they see what they see

---

## References

- GPT-5 consultation (2026-01-26): Fairness strategies, DRR, MMR
- Grok-4 consultation (2026-01-26): FairRecent, per-source queuing architecture
- Google News algorithm: Clustering + source diversity + freshness
- Deficit Round Robin: Network fair queuing literature
